---
title: "Getting started with NetCoupler"
author: 
    - "Clemens Wittenbecher"
    - "Luke Johnston"
date: "`r Sys.Date()`"
bibliography: references.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting started with NetCoupler}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

![](https://img.shields.io/badge/document%20status-rough%20draft-red?style=flat-square)

The goal of NetCoupler is to estimate causal links between a set of -omic (e.g.
metabolomics, lipidomics) or other high-dimensional data and an external variable,
such as a disease outcome, an exposure, or both. The NetCoupler-algorithm,
initially formulated by Clemens Wittenbecher [@Wittenbecher2017], links a conditional
dependency network with an external variable (i.e. an outcome or exposure) to
identify network-independent associations between the network variables and the
external variable, classified as direct effects.

The input given to NetCoupler include:

1. Standardized metabolic or other high-dimensional data.
2. Exposure or outcome data.
3. Network estimating method (default is the PC algorithm [@Colombo2014] from
the [pcalg](https://CRAN.R-project.org/package=pcalg) package).
3. Modeling method (e.g. linear regression with `lm()`), including confounders
to adjust for.

<!-- TODO: Add figure demonstrating NetCoupler -->

The final output is the modeling results along with the results from
NetCoupler's classification. Results can be displayed as a joint network model
in graphical form.

## Overall framework

NetCoupler has several frameworks in mind:

- Works with [magrittr](https://magrittr.tidyverse.org/) `%>%` or base R
`|>` operator.
- Works with [tidyselect](https://tidyselect.r-lib.org/) helpers (e.g.
`starts_with()`, `contains()`).
- Is auto-complete friendly (e.g. start function names with `nc_`).
- Inputs and outputs of functions are in general
[tibbles](https://tibble.tidyverse.org/)/dataframes or [tidygraph tibbles](https://tidygraph.data-imaginist.com/).
- Generic modeling approach by using model and settings as function argument
inputs.

## Workflow

The general workflow for using NetCoupler revolves around the five main
functions:

- `nc_standardize()`: The algorithm in general, but especially the network
estimation method, is sensitive to the values and distribution of the variables.
Scaling the variables by standardizing, mean-centering, and natural log
transforming them are important to making sure more accurate estimations.
- `nc_estimate_network()`: Estimate the connections between metabolic variables
as a undirected graph based on dependencies between variables. This network is
used to identify metabolic variables that are connected to each other as
neighbours.
- `nc_plot_network()`: Visualize the connections estimated from
`nc_estimate_network()`.
- `nc_estimate_exposure_links()` and `nc_estimate_outcome_links()`: Uses the
standardized data and the estimated network to classify the conditionally
independent relationship between each metabolic variable and an external
variable (e.g. an outcome or an exposure) as either being a direct, ambiguous,
or no effect relationship.
- `nc_plot_links()`: Plots the results from the
`nc_estimate_exposure_links()` or 
`nc_estimate_outcome_links()`.

## Simple example

The below is an example using a simulated dataset for demonstrating NetCoupler.

### Estimating the metabolic network

For estimating the network, it's (basically) required to standardize
the metabolic variables before inputting into `nc_estimate_network()`.
This function also log-transforms and scales 
(mean-center and z-score normalize) the values of the metabolic variables.
We do this because the network estimation algorithm can sometimes be finicky
about differences in variable numerical scale (mean of 1 vs mean of 1000).

```{r metabolic-standardize}
library(NetCoupler)
std_metabolic_data <- simulated_data %>% 
    nc_standardize(starts_with("metabolite"))
```

If you intend to also adjust for potential confounders when estimating
the exposure or outcome side connections,
you can include the potential impact these confounders may have on 
the network by regressing the confounders on the metabolic variables.
Then the residuals can be extracted and used when constructing the network.
You do this also with the `nc_standardize()` function. 

```{r metabolic-standardize-residuals, eval=FALSE}
std_metabolic_data <- simulated_data %>% 
    nc_standardize(starts_with("metabolite"),
                   .regressed_on = "age")
```

After that, you can estimate the network.

```{r create-network}
# Make partial independence network from metabolite data
metabolite_network <- std_metabolic_data %>% 
    nc_estimate_network(starts_with("metabolite"))
```

To see what the network looks like,
use the function `nc_plot_network()`.

```{r visualize-metabolic-network, fig.width=5.6, fig.height=4.5}
std_metabolic_data %>%
    nc_plot_network(metabolite_network)
```

While the plot is a bit crowded, it at least provides a base to start tidying up
from.

### Estimating exposure and outcome-side connections

For the exposure and outcome side, 
you should standardize the metabolic variables, 
but this time, we don't regress on the confounders 
since they will be included in the models.

```{r standardize-data}
standardized_data <- simulated_data %>% 
    nc_standardize(starts_with("metabolite"))
```

Now you can estimate the outcome or exposure and identify direct effects
for either the exposure side (`exposure -> metabolite`) 
or the outcome side (`metabolite -> outcome`).
For more details on the algorithm, see the `vignette("description")`.
For the exposure side, 
the function identifies whether a link between the exposure 
and an index node (one metabolic variable in the network) exists,
independent of potential confounders 
and from neighbouring nodes (other metabolic variables linked to the index variable).
Depending on how consistent and strong the link is,
the effect is classified as "direct", "ambiguous", or "none".

In the example below, we specifically generated the simulated data so that
the exposure is associated with metabolites 1, 8, and 12.
And as we can see, those links have been correctly identified.

```{r example-use, cache=TRUE}
outcome_estimates <- standardized_data %>%
    nc_outcome_estimates(
        .edge_tbl = as_edge_tbl(metabolite_network),
        .outcome = "outcome_continuous",
        .model_function = lm
    )
outcome_estimates

exposure_estimates <- standardized_data %>%
    nc_exposure_estimates(
        .edge_tbl = as_edge_tbl(metabolite_network),
        .exposure = "exposure",
        .model_function = lm
    )
exposure_estimates
```

If you want to adjust for confounders and have already used `.regressed_on` in
the `nc_standardize()` function, add confounders to `nc_estimate_outcome_links()`
or `nc_estimate_exposure_links()` with the `.adjustment_vars` argument:

```{r estimation-adjustment, eval=FALSE}
outcome_estimates <- standardized_data %>%
    nc_outcome_estimates(
        .edge_tbl = as_edge_tbl(metabolite_network),
        .outcome = "outcome_continuous",
        .model_function = lm,
        .adjustment_vars = "age"
    )
```

### Plotting 

To visualize the results of the linked network graph and the effect
classification, there are two functions to show the exposure and the outcome
plots. In general, these plot functions are currently mostly for exploratory
purposes and are too "busy" and crowded to be meaningful for presentation or
publication. However, these are good starting points for making prettier,
more legible plots.

```{r plot-outcome-estimation-networks, fig.width=7, fig.height=6}
nc_plot_outcome_estimation(
    standardized_data,
    metabolite_network,
    outcome_estimates
)
```

```{r plot-exposure-estimation-networks, fig.width=7, fig.height=6}
nc_plot_exposure_estimation(
    standardized_data,
    metabolite_network,
    exposure_estimates
)
```

<!-- ## Slow code? Use parallel processing with future -->

<!-- If the analysis is taking a while, you can use the future package to speed things -->
<!-- up by implementing parallel processing. Set the `.parallel` argument to `TRUE` -->
<!-- in either `nc_outcome_estimates()` or `nc_exposure_estimates()` and then use -->
<!-- the future package with a given `plan()`. If you use RStudio, the only usable -->
<!-- strategy is `multisession`. After you run your code, close up the parallel -->
<!-- processing by putting it back to normal with `plan(sequential)`. Using the future -->
<!-- package you can speed up the processing by almost 2.5 times. -->

<!-- ```{r future-parallel-processing, eval=FALSE} -->
<!-- library(future) -->
<!-- plan(multisession) -->
<!-- outcome_estimates <- standardized_data %>% -->
<!--     nc_outcome_estimates( -->
<!--         .edge_tbl = as_edge_tbl(metabolite_network), -->
<!--         .outcome = "outcome_continuous", -->
<!--         .model_function = lm, -->
<!--         .parallel = TRUE -->
<!--     ) -->
<!-- plan(sequential) -->
<!-- ``` -->
